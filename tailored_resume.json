{
    "summary": "Machine Learning Engineer adept at designing, implementing, and evaluating biomedical foundation models and large language models (LLMs), with scientific rigor for applications focused on therapeutics and prognostics. Proven ability to deliver production-grade AI/ML pipelines on AWS, achieving significant performance optimizations (78% predictive accuracy, latency reduction to <200ms). Expertise in Python, TensorFlow, PyTorch, and MLOps tools (Kubernetes, MLflow, Docker) honed over 4+ years.",
    "work_experience": "## Work Experience\n\n**Senior AI/ML Engineer** | **ScriptChain Health** | Washington, DC\nMay 2024 – Present\n* Developed deep learning models to predict 30-day hospital readmissions with 78% accuracy, enabling earlier interventions across HIPAA-compliant hospitals. \n* Reduced model deployment time by 96% using Cloud Build, achieving P95 latency ≤200ms at 1K RPS and ensuring rapid model iteration.\n* Automated model promotion via MLflow A/B tests in Vertex AI, improving PR AUC by +6pp and reducing false positives by 8% for enhanced model selection.\n* Optimized Spark ETL pipelines processing 500M+ rows on AWS (S3, Glue, Athena), decreasing preprocessing time by 99% and GPU memory usage by 50%, saving $6K annually.\n\n**Data Consultant** | **George Washington University** | Washington, DC\nSeptember 2024 – Present\n* Guided 10+ research studies across economics, biology, and NLP, mentoring students in regression analysis, hypothesis testing, and cross-validation using R and Python.\n* Empowered 100+ students and faculty through workshops on ML modeling, evaluation, and responsible AI practices, fostering data literacy and ethical AI development.\n\n**Digital Transformation Developer** | **Tata Consultancy Services** | India \nApril 2021 - August 2023 \n* Automated workflows for 14+ client teams using custom scripts and tools, reducing manual effort by 40% and driving significant cost savings.\n* Analyzed client requirements and implemented data-driven process improvements, achieving 100% adoption across all use cases and maximizing operational efficiency.",
    "technical_skills": "## Technical Skills\n\n**Programming Languages:** Python, SQL, C++ \n**ML Frameworks & Libraries:** PyTorch, TensorFlow, scikit-learn, Huggingface APIs, Transformers\n**MLOps & Cloud:** AWS (S3, EC2), Docker, Git, MLflow, CI/CD \n**Data Engineering:** Data Preprocessing, ETL Pipelines, Spark, Model Monitoring & Evaluation",
    "projects": "## Rewritten Projects Section:\n\n**Intelligent Building Code QA | _NLP, RAG_** \n* Developed a Retrieval-Augmented Generation (RAG) pipeline using Sentence Transformers and GPT-4 via the OpenAI API to power a custom Q&A system for complex construction code queries.\n* Achieved a 98% improvement in response efficiency for complex code queries, significantly reducing manual lookup time for architects. Deployed the solution as an interactive web app using Streamlit. \n\n**AI-Text Discriminator | _NLP, Transformers_**\n* Built an NLP pipeline to classify human-written vs. LLM-generated text, fine-tuning BERT and GPT detector models on a 1.2 million text dataset.\n* Achieved 97% classification accuracy through robust training, hyperparameter tuning, and ensemble model stacking with scikit-learn. Analyzed model confidence thresholds for real-world deployment and visualized insights using Matplotlib and Seaborn."
}